{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 10 – Building Neural Networks with PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code and solutions to the exercises in chapter 10._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ageron/handson-mlp/blob/main/10_neural_nets_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-mlp/blob/main/10_neural_nets_with_pytorch.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project requires Python 3.10 or above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "assert sys.version_info >= (3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also requires Scikit-Learn ≥ 1.6.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging.version import Version\n",
    "import sklearn\n",
    "\n",
    "assert Version(sklearn.__version__) >= Version(\"1.6.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we using Colab or Kaggle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using Colab, a couple libraries are not pre-installed so we must install them manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/400.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "if IS_COLAB:\n",
    "    %pip install -q optuna torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course we need PyTorch, specifically PyTorch ≥ 2.6.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "assert Version(torch.__version__) >= Version(\"2.6.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in earlier chapters, let's define the default font sizes to make the figures prettier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Fundamentals\n",
    "## PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 7.],\n",
       "        [2., 3., 6.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.tensor([[1.0, 4.0, 7.0], [2.0, 3.0, 6.0]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 3.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20., 50., 80.],\n",
       "        [30., 40., 70.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 * (X + 1.0)  # item-wise addition and multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2.7183,   54.5981, 1096.6332],\n",
       "        [   7.3891,   20.0855,  403.4288]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8333)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([2., 4., 7.]),\n",
       "indices=tensor([1, 0, 0]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[66., 56.],\n",
       "        [56., 49.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X @ X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 4., 7.],\n",
       "       [2., 3., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 7.],\n",
       "        [2., 3., 6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([[1., 4., 7.], [2., 3., 6.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 7.],\n",
       "        [2., 3., 6.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([[1., 4., 7.], [2., 3., 6.]]), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 7.],\n",
       "        [2., 3., 6.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(np.array([[1., 4., 7.], [2., 3., 6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., 88.,  7.],\n",
       "        [ 2.,  3.,  6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code: demonstrate torch.from_numpy()\n",
    "X2_np = np.array([[1., 4., 7.], [2., 3., 6]])\n",
    "X2 = torch.from_numpy(X2_np)  # X2_np and X2 share the same data in memory\n",
    "X2_np[0, 1] = 88\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1., -99.,   7.],\n",
       "        [  2., -99.,   6.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 1] = -99\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 7.],\n",
       "        [2., 0., 6.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.relu_()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch tensors really resemble NumPy arrays. In fact, they have over 200 common functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'__getattr__, abs, absolute, acos, acosh, add, all, allclose, amax, amin, angle, any, arange, arccos, arccosh, arcsin, arcsinh, arctan, arctan2, arctanh, argmax, argmin, argsort, argwhere, asarray, asin, asinh, atan, atan2, atanh, atleast_1d, atleast_2d, atleast_3d, bincount, bitwise_and, bitwise_left_shift, bitwise_not, bitwise_or, bitwise_right_shift, bitwise_xor, broadcast_shapes, broadcast_to, can_cast, ceil, clip, column_stack, concat, concatenate, conj, copysign, corrcoef, cos, cosh, count_nonzero, cov, cross, cumprod, cumsum, deg2rad, diag, diagflat, diagonal, diff, divide, dot, dsplit, dstack, dtype, einsum, empty, empty_like, equal, exp, exp2, expm1, eye, finfo, fix, flip, fliplr, flipud, float_power, floor, floor_divide, fmax, fmin, fmod, frexp, from_dlpack, frombuffer, full, full_like, gcd, gradient, greater, greater_equal, heaviside, histogram, histogramdd, hsplit, hstack, hypot, i0, iinfo, imag, inner, isclose, isfinite, isin, isinf, isnan, isneginf, isposinf, isreal, kron, lcm, ldexp, less, less_equal, linspace, load, log, log10, log1p, log2, logaddexp, logaddexp2, logical_and, logical_not, logical_or, logical_xor, logspace, matmul, max, maximum, mean, median, meshgrid, min, minimum, moveaxis, multiply, nan_to_num, nanmean, nanmedian, nanquantile, nansum, negative, nextafter, nonzero, not_equal, ones, ones_like, outer, positive, pow, prod, promote_types, put, quantile, rad2deg, ravel, real, reciprocal, remainder, reshape, result_type, roll, rot90, round, row_stack, save, searchsorted, select, set_printoptions, sign, signbit, sin, sinc, sinh, sort, split, sqrt, square, squeeze, stack, std, subtract, sum, swapaxes, take, tan, tanh, tensordot, tile, trace, transpose, trapezoid, trapz, tril, tril_indices, triu, triu_indices, true_divide, trunc, typename, unique, unravel_index, vander, var, vdot, vsplit, vstack, where, zeros, zeros_like'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code: list functions that appear both in NumPy and PyTorch\n",
    "functions = lambda mod: set(f for f in dir(mod) if callable(getattr(mod, f)))\n",
    "\", \".join(sorted(functions(torch) & functions(np)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
    "M = M.to(device)\n",
    "M.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = torch.tensor([[1., 2., 3.], [4., 5., 6.]], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14., 32.],\n",
       "        [32., 77.]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = M @ M.T  # run some operations on the GPU\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.1 ms ± 2.17 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "549 µs ± 3.99 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "M = torch.rand((1000, 1000))  # on the CPU\n",
    "M @ M.T  # warmup\n",
    "%timeit M @ M.T\n",
    "\n",
    "M = M.to(device)\n",
    "M @ M.T  # warmup\n",
    "%timeit M @ M.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a simple function, $f(x) = x^2$.\n",
    "Calculus tells us that the derivative of this function is $f'(x)=2x$. Let's evaluate $f(5)$ and the derivative $f'(5)$ using autograd. We expect to find $f(5)=5^2=25$ and $f'(5)=2*5=10$. Let's see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "f = x ** 2\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "with torch.no_grad():\n",
    "    x -= learning_rate * x.grad  # gradient descent step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could have used this code for the gradient descent step (but using `no_grad()` is more common for this):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_detached = x.detach()\n",
    "x_detached -= learning_rate * x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put everything together to get our training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "for iteration in range(100):\n",
    "    f = x ** 2  # forward pass\n",
    "    f.backward()  # backward pass\n",
    "    with torch.no_grad():\n",
    "        x -= learning_rate * x.grad  # gradient descent step\n",
    "    x.grad.zero_()  # reset the gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `x` gets pushed towards 0, since that's the value that minimizes $f(x) = x^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0185e-09, requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Linear Regression\n",
    "## Linear Regression Using Tensors & Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_valid = torch.FloatTensor(X_valid)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "means = X_train.mean(dim=0, keepdims=True)\n",
    "stds = X_train.std(dim=0, keepdims=True)\n",
    "X_train = (X_train - means) / stds\n",
    "X_valid = (X_valid - means) / stds\n",
    "X_test = (X_test - means) / stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch expects the targets to have one row per sample, so let's reshape the targets to be column vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.FloatTensor(y_train).view(-1, 1)\n",
    "y_valid = torch.FloatTensor(y_valid).view(-1, 1)\n",
    "y_test = torch.FloatTensor(y_test).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "n_features = X_train.shape[1]  # there are 8 input features\n",
    "w = torch.randn((n_features, 1), requires_grad=True)\n",
    "b = torch.tensor(0., requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: in the next section, we will build an almost identical model using PyTorch's high-level API. Its results will be slightly different because it will use a different parameter initialization method: it will use a uniform random distribution from $-\\frac{1}{2\\sqrt 2}$ to $+\\frac{1}{2\\sqrt 2}$ to initialize both the weights and the bias term. If you want to get exactly the same result here as in the next section, you can uncomment and run the initialization code in the following cell, instead of the code in the previous cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "# n_features = X_train.shape[1]  # there are 8 input features\n",
    "# r = 2 ** -1.5  # this is equal to 1 / 2√2\n",
    "# w = torch.empty(n_features, 1).uniform_(-r, r)\n",
    "# b = torch.empty(1).uniform_(-r, r)\n",
    "# w.requires_grad_(True)\n",
    "# b.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 16.158456802368164\n",
      "Epoch 2/20, Loss: 4.8793745040893555\n",
      "Epoch 3/20, Loss: 2.255225419998169\n",
      "Epoch 4/20, Loss: 1.3307634592056274\n",
      "Epoch 5/20, Loss: 0.9680691957473755\n",
      "Epoch 6/20, Loss: 0.8142675757408142\n",
      "Epoch 7/20, Loss: 0.7417045831680298\n",
      "Epoch 8/20, Loss: 0.7020701169967651\n",
      "Epoch 9/20, Loss: 0.6765918731689453\n",
      "Epoch 10/20, Loss: 0.6577965021133423\n",
      "Epoch 11/20, Loss: 0.6426151990890503\n",
      "Epoch 12/20, Loss: 0.6297222971916199\n",
      "Epoch 13/20, Loss: 0.6184942126274109\n",
      "Epoch 14/20, Loss: 0.6085968613624573\n",
      "Epoch 15/20, Loss: 0.5998216867446899\n",
      "Epoch 16/20, Loss: 0.592018723487854\n",
      "Epoch 17/20, Loss: 0.5850691795349121\n",
      "Epoch 18/20, Loss: 0.578873336315155\n",
      "Epoch 19/20, Loss: 0.573345422744751\n",
      "Epoch 20/20, Loss: 0.5684100389480591\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.4\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = X_train @ w + b\n",
    "    loss = ((y_pred - y_train) ** 2).mean()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        b -= learning_rate * b.grad\n",
    "        w -= learning_rate * w.grad\n",
    "        b.grad.zero_()\n",
    "        w.grad.zero_()\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]  # pretend these are new instances\n",
    "with torch.no_grad():\n",
    "    y_pred = X_new @ w + b  # use the trained parameters to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8916],\n",
       "        [1.6480],\n",
       "        [2.6577]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Using PyTorch's High-Level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(42)  # to get reproducible results\n",
    "model = nn.Linear(in_features=n_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.3117], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3117], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4718],\n",
       "        [ 0.1131]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bgd(model, optimizer, criterion, X_train, y_train, n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 4.3378496170043945\n",
      "Epoch 2/20, Loss: 0.7802939414978027\n",
      "Epoch 3/20, Loss: 0.6253842115402222\n",
      "Epoch 4/20, Loss: 0.6060433983802795\n",
      "Epoch 5/20, Loss: 0.5956299304962158\n",
      "Epoch 6/20, Loss: 0.587356686592102\n",
      "Epoch 7/20, Loss: 0.5802990794181824\n",
      "Epoch 8/20, Loss: 0.5741382837295532\n",
      "Epoch 9/20, Loss: 0.5687101483345032\n",
      "Epoch 10/20, Loss: 0.5639079809188843\n",
      "Epoch 11/20, Loss: 0.5596511363983154\n",
      "Epoch 12/20, Loss: 0.5558737516403198\n",
      "Epoch 13/20, Loss: 0.5525194406509399\n",
      "Epoch 14/20, Loss: 0.5495392084121704\n",
      "Epoch 15/20, Loss: 0.5468900203704834\n",
      "Epoch 16/20, Loss: 0.544533908367157\n",
      "Epoch 17/20, Loss: 0.5424376726150513\n",
      "Epoch 18/20, Loss: 0.5405716300010681\n",
      "Epoch 19/20, Loss: 0.5389097332954407\n",
      "Epoch 20/20, Loss: 0.5374288558959961\n"
     ]
    }
   ],
   "source": [
    "train_bgd(model, optimizer, mse, X_train, y_train, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8061],\n",
       "        [1.7116],\n",
       "        [2.6973]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]  # pretend these are new instances\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_new)  # use the trained model to make predictions\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Regression MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 5.045480251312256\n",
      "Epoch 2/20, Loss: 2.0523123741149902\n",
      "Epoch 3/20, Loss: 1.0039883852005005\n",
      "Epoch 4/20, Loss: 0.8570139408111572\n",
      "Epoch 5/20, Loss: 0.7740675210952759\n",
      "Epoch 6/20, Loss: 0.7225847244262695\n",
      "Epoch 7/20, Loss: 0.6893726587295532\n",
      "Epoch 8/20, Loss: 0.6669032573699951\n",
      "Epoch 9/20, Loss: 0.6507738828659058\n",
      "Epoch 10/20, Loss: 0.6383934020996094\n",
      "Epoch 11/20, Loss: 0.6281993389129639\n",
      "Epoch 12/20, Loss: 0.6193399429321289\n",
      "Epoch 13/20, Loss: 0.6113173365592957\n",
      "Epoch 14/20, Loss: 0.6038705706596375\n",
      "Epoch 15/20, Loss: 0.5968307852745056\n",
      "Epoch 16/20, Loss: 0.5901119112968445\n",
      "Epoch 17/20, Loss: 0.5836468935012817\n",
      "Epoch 18/20, Loss: 0.5774063467979431\n",
      "Epoch 19/20, Loss: 0.5713554620742798\n",
      "Epoch 20/20, Loss: 0.565444827079773\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "mse = nn.MSELoss()\n",
    "train_bgd(model, optimizer, mse, X_train, y_train, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Mini-Batch Gradient Descent using DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – build the model just like earlier\n",
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 50), nn.ReLU(),\n",
    "    nn.Linear(50, 40), nn.ReLU(),\n",
    "    nn.Linear(40, 1)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# extra code – build the optimizer and loss function, as earlier\n",
    "learning_rate = 0.02\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, n_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {mean_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.5900\n",
      "Epoch 2/20, Loss: 0.4046\n",
      "Epoch 3/20, Loss: 0.3801\n",
      "Epoch 4/20, Loss: 0.3629\n",
      "Epoch 5/20, Loss: 0.3529\n",
      "Epoch 6/20, Loss: 0.3520\n",
      "Epoch 7/20, Loss: 0.3408\n",
      "Epoch 8/20, Loss: 0.3427\n",
      "Epoch 9/20, Loss: 0.3406\n",
      "Epoch 10/20, Loss: 0.3378\n",
      "Epoch 11/20, Loss: 0.3304\n",
      "Epoch 12/20, Loss: 0.3267\n",
      "Epoch 13/20, Loss: 0.3244\n",
      "Epoch 14/20, Loss: 0.3221\n",
      "Epoch 15/20, Loss: 0.3186\n",
      "Epoch 16/20, Loss: 0.3149\n",
      "Epoch 17/20, Loss: 0.3123\n",
      "Epoch 18/20, Loss: 0.3111\n",
      "Epoch 19/20, Loss: 0.3088\n",
      "Epoch 20/20, Loss: 0.3072\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, mse, train_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, metric_fn, aggregate_fn=torch.mean):\n",
    "    model.eval()\n",
    "    metrics = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            metric = metric_fn(y_pred, y_batch)\n",
    "            metrics.append(metric)\n",
    "    return aggregate_fn(torch.stack(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4080, device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = TensorDataset(X_valid, y_valid)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
    "valid_mse = evaluate(model, valid_loader, mse)\n",
    "valid_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5668, device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rmse(y_pred, y_true):\n",
    "    return ((y_pred - y_true) ** 2).mean().sqrt()\n",
    "\n",
    "evaluate(model, valid_loader, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6388, device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_mse.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6388, device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, valid_loader, mse,\n",
    "         aggregate_fn=lambda metrics: torch.sqrt(torch.mean(metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "def evaluate_tm(model, data_loader, metric):\n",
    "    model.eval()\n",
    "    metric.reset()  # reset the metric at the beginning\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            metric.update(y_pred, y_batch)  # update it at each iteration\n",
    "    return metric.compute()  # compute the final result at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6388, device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "evaluate_tm(model, valid_loader, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 0.7826, train metric: 0.8847, valid metric: 0.6690\n",
      "Epoch 2/20, train loss: 0.4362, train metric: 0.6605, valid metric: 0.6099\n",
      "Epoch 3/20, train loss: 0.3930, train metric: 0.6269, valid metric: 0.6145\n",
      "Epoch 4/20, train loss: 0.3759, train metric: 0.6132, valid metric: 0.5963\n",
      "Epoch 5/20, train loss: 0.3649, train metric: 0.6040, valid metric: 0.5911\n",
      "Epoch 6/20, train loss: 0.3598, train metric: 0.5999, valid metric: 0.5965\n",
      "Epoch 7/20, train loss: 0.3530, train metric: 0.5941, valid metric: 0.6061\n",
      "Epoch 8/20, train loss: 0.3495, train metric: 0.5911, valid metric: 0.6043\n",
      "Epoch 9/20, train loss: 0.3455, train metric: 0.5877, valid metric: 0.5723\n",
      "Epoch 10/20, train loss: 0.3416, train metric: 0.5846, valid metric: 0.6043\n",
      "Epoch 11/20, train loss: 0.3401, train metric: 0.5831, valid metric: 0.5882\n",
      "Epoch 12/20, train loss: 0.3362, train metric: 0.5799, valid metric: 0.5738\n",
      "Epoch 13/20, train loss: 0.3352, train metric: 0.5788, valid metric: 0.5873\n",
      "Epoch 14/20, train loss: 0.3310, train metric: 0.5754, valid metric: 0.5884\n",
      "Epoch 15/20, train loss: 0.3291, train metric: 0.5736, valid metric: 0.5608\n",
      "Epoch 16/20, train loss: 0.3272, train metric: 0.5721, valid metric: 0.5747\n",
      "Epoch 17/20, train loss: 0.3264, train metric: 0.5714, valid metric: 0.5839\n",
      "Epoch 18/20, train loss: 0.3238, train metric: 0.5691, valid metric: 0.5661\n",
      "Epoch 19/20, train loss: 0.3207, train metric: 0.5663, valid metric: 0.5556\n",
      "Epoch 20/20, train loss: 0.3190, train metric: 0.5649, valid metric: 0.5617\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train2(model, optimizer, criterion, metric, train_loader, valid_loader,\n",
    "               n_epochs):\n",
    "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        metric.reset()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            model.train()\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            metric.update(y_pred, y_batch)\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        history[\"train_losses\"].append(mean_loss)\n",
    "        history[\"train_metrics\"].append(metric.compute().item())\n",
    "        history[\"valid_metrics\"].append(\n",
    "            evaluate_tm(model, valid_loader, metric).item())\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
    "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
    "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
    "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
    "    return history\n",
    "\n",
    "torch.manual_seed(42)\n",
    "learning_rate = 0.01\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 50), nn.ReLU(),\n",
    "    nn.Linear(50, 40), nn.ReLU(),\n",
    "    nn.Linear(40, 30), nn.ReLU(),\n",
    "    nn.Linear(30, 1)\n",
    ")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()\n",
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "history = train2(model, optimizer, mse, rmse, train_loader, valid_loader,\n",
    "                 n_epochs)\n",
    "\n",
    "# Since we compute the training metric\n",
    "plt.plot(np.arange(n_epochs) + 0.5, history[\"train_metrics\"], \".--\",\n",
    "         label=\"Training\")\n",
    "plt.plot(np.arange(n_epochs) + 1.0, history[\"valid_metrics\"], \".-\",\n",
    "         label=\"Validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.grid()\n",
    "plt.title(\"Learning curves\")\n",
    "plt.axis([0.5, 20, 0.4, 1.0])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Nonsequential Models Using Custom Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.deep_stack = nn.Sequential(\n",
    "            nn.Linear(n_features, 50), nn.ReLU(),\n",
    "            nn.Linear(50, 40), nn.ReLU(),\n",
    "            nn.Linear(40, 30), nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(30 + n_features, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        deep_output = self.deep_stack(X)\n",
    "        wide_and_deep = torch.concat([X, deep_output], dim=1)\n",
    "        return self.output_layer(wide_and_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = WideAndDeep(n_features).to(device)\n",
    "learning_rate = 0.002  # the model changed, so did the optimal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 1.7802, train metric: 1.3344, valid metric: 0.8690\n",
      "Epoch 2/20, train loss: 0.6201, train metric: 0.7875, valid metric: 0.9492\n",
      "Epoch 3/20, train loss: 0.5900, train metric: 0.7682, valid metric: 0.7331\n",
      "Epoch 4/20, train loss: 0.5607, train metric: 0.7488, valid metric: 0.7771\n",
      "Epoch 5/20, train loss: 0.5408, train metric: 0.7353, valid metric: 0.7967\n",
      "Epoch 6/20, train loss: 0.5244, train metric: 0.7241, valid metric: 0.7098\n",
      "Epoch 7/20, train loss: 0.5070, train metric: 0.7119, valid metric: 0.7419\n",
      "Epoch 8/20, train loss: 0.4941, train metric: 0.7030, valid metric: 0.6750\n",
      "Epoch 9/20, train loss: 0.4798, train metric: 0.6928, valid metric: 0.6762\n",
      "Epoch 10/20, train loss: 0.4657, train metric: 0.6825, valid metric: 0.6678\n",
      "Epoch 11/20, train loss: 0.4538, train metric: 0.6736, valid metric: 0.6617\n",
      "Epoch 12/20, train loss: 0.4441, train metric: 0.6665, valid metric: 0.6651\n",
      "Epoch 13/20, train loss: 0.4328, train metric: 0.6580, valid metric: 0.6803\n",
      "Epoch 14/20, train loss: 0.4232, train metric: 0.6506, valid metric: 0.6288\n",
      "Epoch 15/20, train loss: 0.4139, train metric: 0.6434, valid metric: 0.6202\n",
      "Epoch 16/20, train loss: 0.4063, train metric: 0.6374, valid metric: 0.6216\n",
      "Epoch 17/20, train loss: 0.3991, train metric: 0.6317, valid metric: 0.6129\n",
      "Epoch 18/20, train loss: 0.3937, train metric: 0.6274, valid metric: 0.6031\n",
      "Epoch 19/20, train loss: 0.3879, train metric: 0.6228, valid metric: 0.6092\n",
      "Epoch 20/20, train loss: 0.3834, train metric: 0.6193, valid metric: 0.5957\n"
     ]
    }
   ],
   "source": [
    "# extra code: train the model, exactly our previous models\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()\n",
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "history = train2(model, optimizer, mse, rmse, train_loader, valid_loader,\n",
    "                 n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepV2(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.deep_stack = nn.Sequential(\n",
    "            nn.Linear(n_features - 2, 50), nn.ReLU(),\n",
    "            nn.Linear(50, 40), nn.ReLU(),\n",
    "            nn.Linear(40, 30), nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(30 + 5, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X_wide = X[:, :5]\n",
    "        X_deep = X[:, 2:]\n",
    "        deep_output = self.deep_stack(X_deep)\n",
    "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
    "        return self.output_layer(wide_and_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = WideAndDeepV2(n_features).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 1.8482, train metric: 1.3598, valid metric: 0.9100\n",
      "Epoch 2/20, train loss: 0.6282, train metric: 0.7927, valid metric: 0.8028\n",
      "Epoch 3/20, train loss: 0.5763, train metric: 0.7591, valid metric: 0.7567\n",
      "Epoch 4/20, train loss: 0.5413, train metric: 0.7356, valid metric: 0.7290\n",
      "Epoch 5/20, train loss: 0.5099, train metric: 0.7142, valid metric: 0.7011\n",
      "Epoch 6/20, train loss: 0.4841, train metric: 0.6958, valid metric: 0.6816\n",
      "Epoch 7/20, train loss: 0.4656, train metric: 0.6824, valid metric: 0.6670\n",
      "Epoch 8/20, train loss: 0.4526, train metric: 0.6728, valid metric: 0.6576\n",
      "Epoch 9/20, train loss: 0.4438, train metric: 0.6662, valid metric: 0.6539\n",
      "Epoch 10/20, train loss: 0.4380, train metric: 0.6618, valid metric: 0.6498\n",
      "Epoch 11/20, train loss: 0.4326, train metric: 0.6577, valid metric: 0.6470\n",
      "Epoch 12/20, train loss: 0.4284, train metric: 0.6546, valid metric: 0.6447\n",
      "Epoch 13/20, train loss: 0.4253, train metric: 0.6521, valid metric: 0.6452\n",
      "Epoch 14/20, train loss: 0.4216, train metric: 0.6494, valid metric: 0.6468\n",
      "Epoch 15/20, train loss: 0.4190, train metric: 0.6473, valid metric: 0.6484\n",
      "Epoch 16/20, train loss: 0.4169, train metric: 0.6458, valid metric: 0.6452\n",
      "Epoch 17/20, train loss: 0.4144, train metric: 0.6438, valid metric: 0.6459\n",
      "Epoch 18/20, train loss: 0.4118, train metric: 0.6417, valid metric: 0.6470\n",
      "Epoch 19/20, train loss: 0.4101, train metric: 0.6404, valid metric: 0.6475\n",
      "Epoch 20/20, train loss: 0.4082, train metric: 0.6389, valid metric: 0.6493\n"
     ]
    }
   ],
   "source": [
    "# extra code: train the model, exactly our previous models\n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()\n",
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "history = train2(model, optimizer, mse, rmse, train_loader, valid_loader,\n",
    "                 n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models with Multiple Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepV3(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.deep_stack = nn.Sequential(\n",
    "            nn.Linear(n_features - 2, 50), nn.ReLU(),\n",
    "            nn.Linear(50, 40), nn.ReLU(),\n",
    "            nn.Linear(40, 30), nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(30 + 5, 1)\n",
    "\n",
    "    def forward(self, X_wide, X_deep):\n",
    "        deep_output = self.deep_stack(X_deep)\n",
    "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
    "        return self.output_layer(wide_and_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "train_data_wd = TensorDataset(X_train[:, :5], X_train[:, 2:], y_train)\n",
    "train_loader_wd = DataLoader(train_data_wd, batch_size=32, shuffle=True)\n",
    "valid_data_wd = TensorDataset(X_valid[:, :5], X_valid[:, 2:], y_valid)\n",
    "valid_loader_wd = DataLoader(valid_data_wd, batch_size=32)\n",
    "test_data_wd = TensorDataset(X_test[:, :5], X_test[:, 2:], y_test)\n",
    "test_loader_wd = DataLoader(test_data_wd, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 0.8366, train metric: 0.9148, valid metric: 0.6892\n",
      "Epoch 2/20, train loss: 0.4627, train metric: 0.6803, valid metric: 0.6455\n",
      "Epoch 3/20, train loss: 0.4319, train metric: 0.6572, valid metric: 0.6374\n",
      "Epoch 4/20, train loss: 0.4259, train metric: 0.6525, valid metric: 0.6512\n",
      "Epoch 5/20, train loss: 0.4120, train metric: 0.6420, valid metric: 0.6305\n",
      "Epoch 6/20, train loss: 0.4040, train metric: 0.6356, valid metric: 0.6287\n",
      "Epoch 7/20, train loss: 0.4005, train metric: 0.6330, valid metric: 0.6252\n",
      "Epoch 8/20, train loss: 0.3976, train metric: 0.6306, valid metric: 0.6158\n",
      "Epoch 9/20, train loss: 0.3883, train metric: 0.6230, valid metric: 0.7407\n",
      "Epoch 10/20, train loss: 0.3866, train metric: 0.6218, valid metric: 0.6063\n",
      "Epoch 11/20, train loss: 0.3752, train metric: 0.6125, valid metric: 0.5974\n",
      "Epoch 12/20, train loss: 0.3704, train metric: 0.6087, valid metric: 0.5888\n",
      "Epoch 13/20, train loss: 0.3677, train metric: 0.6063, valid metric: 0.5981\n",
      "Epoch 14/20, train loss: 0.3604, train metric: 0.6004, valid metric: 0.5842\n",
      "Epoch 15/20, train loss: 0.3592, train metric: 0.5994, valid metric: 0.6410\n",
      "Epoch 16/20, train loss: 0.3640, train metric: 0.6034, valid metric: 0.5747\n",
      "Epoch 17/20, train loss: 0.3534, train metric: 0.5946, valid metric: 0.5686\n",
      "Epoch 18/20, train loss: 0.3461, train metric: 0.5883, valid metric: 0.5679\n",
      "Epoch 19/20, train loss: 0.3436, train metric: 0.5863, valid metric: 0.5621\n",
      "Epoch 20/20, train loss: 0.3414, train metric: 0.5843, valid metric: 0.5690\n"
     ]
    }
   ],
   "source": [
    "def evaluate_multi_in(model, data_loader, metric):\n",
    "    model.eval()\n",
    "    metric.reset()  # reset the metric at the beginning\n",
    "    with torch.no_grad():\n",
    "        for X_batch_wide, X_batch_deep, y_batch in data_loader:\n",
    "            X_batch_wide = X_batch_wide.to(device)\n",
    "            X_batch_deep = X_batch_deep.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(X_batch_wide, X_batch_deep)\n",
    "            metric.update(y_pred, y_batch)  # update it at each iteration\n",
    "    return metric.compute()  # compute the final result at the end\n",
    "\n",
    "def train_multi_in(model, optimizer, criterion, metric, train_loader,\n",
    "                   valid_loader, n_epochs):\n",
    "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        metric.reset()\n",
    "        for *X_batch_inputs, y_batch in train_loader:\n",
    "            model.train()\n",
    "            X_batch_inputs = [X.to(device) for X in X_batch_inputs]\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(*X_batch_inputs)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            metric.update(y_pred, y_batch)\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        history[\"train_losses\"].append(mean_loss)\n",
    "        history[\"train_metrics\"].append(metric.compute().item())\n",
    "        history[\"valid_metrics\"].append(\n",
    "            evaluate_multi_in(model, valid_loader, metric).item())\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
    "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
    "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
    "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
    "    return history\n",
    "\n",
    "torch.manual_seed(42)\n",
    "learning_rate = 0.01\n",
    "model = WideAndDeepV3(n_features).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()\n",
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "history = train_multi_in(model, optimizer, mse, rmse, train_loader_wd,\n",
    "                         valid_loader_wd, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_wide, X_deep, y):\n",
    "        self.X_wide = X_wide\n",
    "        self.X_deep = X_deep\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_dict = {\"X_wide\": self.X_wide[idx], \"X_deep\": self.X_deep[idx]}\n",
    "        return input_dict, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "train_data_named = WideAndDeepDataset(\n",
    "    X_wide=X_train[:, :5], X_deep=X_train[:, 2:], y=y_train)\n",
    "train_loader_named = DataLoader(train_data_named, batch_size=32, shuffle=True)\n",
    "valid_data_named = WideAndDeepDataset(\n",
    "    X_wide=X_valid[:, :5], X_deep=X_valid[:, 2:], y=y_valid)\n",
    "valid_loader_named = DataLoader(valid_data_named, batch_size=32)\n",
    "test_data_named = WideAndDeepDataset(\n",
    "    X_wide=X_test[:, :5], X_deep=X_test[:, 2:], y=y_test)\n",
    "test_loader_named = DataLoader(test_data_named, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 0.8366, train metric: 0.9148, valid metric: 0.6892\n",
      "Epoch 2/20, train loss: 0.4627, train metric: 0.6803, valid metric: 0.6455\n",
      "Epoch 3/20, train loss: 0.4319, train metric: 0.6572, valid metric: 0.6374\n",
      "Epoch 4/20, train loss: 0.4259, train metric: 0.6525, valid metric: 0.6512\n",
      "Epoch 5/20, train loss: 0.4120, train metric: 0.6420, valid metric: 0.6305\n",
      "Epoch 6/20, train loss: 0.4040, train metric: 0.6356, valid metric: 0.6287\n",
      "Epoch 7/20, train loss: 0.4005, train metric: 0.6330, valid metric: 0.6252\n",
      "Epoch 8/20, train loss: 0.3976, train metric: 0.6306, valid metric: 0.6158\n",
      "Epoch 9/20, train loss: 0.3883, train metric: 0.6230, valid metric: 0.7407\n",
      "Epoch 10/20, train loss: 0.3866, train metric: 0.6218, valid metric: 0.6063\n",
      "Epoch 11/20, train loss: 0.3752, train metric: 0.6125, valid metric: 0.5974\n",
      "Epoch 12/20, train loss: 0.3704, train metric: 0.6087, valid metric: 0.5888\n",
      "Epoch 13/20, train loss: 0.3677, train metric: 0.6063, valid metric: 0.5981\n",
      "Epoch 14/20, train loss: 0.3604, train metric: 0.6004, valid metric: 0.5842\n",
      "Epoch 15/20, train loss: 0.3592, train metric: 0.5994, valid metric: 0.6410\n",
      "Epoch 16/20, train loss: 0.3640, train metric: 0.6034, valid metric: 0.5747\n",
      "Epoch 17/20, train loss: 0.3534, train metric: 0.5946, valid metric: 0.5686\n",
      "Epoch 18/20, train loss: 0.3461, train metric: 0.5883, valid metric: 0.5679\n",
      "Epoch 19/20, train loss: 0.3436, train metric: 0.5863, valid metric: 0.5621\n",
      "Epoch 20/20, train loss: 0.3414, train metric: 0.5843, valid metric: 0.5690\n"
     ]
    }
   ],
   "source": [
    "def evaluate_named(model, data_loader, metric):\n",
    "    model.eval()\n",
    "    metric.reset()  # reset the metric at the beginning\n",
    "    with torch.no_grad():\n",
    "        for inputs, y_batch in data_loader:\n",
    "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(X_wide=inputs[\"X_wide\"], X_deep=inputs[\"X_deep\"])\n",
    "            metric.update(y_pred, y_batch)\n",
    "    return metric.compute()  # compute the final result at the end\n",
    "\n",
    "def train_named(model, optimizer, criterion, metric, train_loader,\n",
    "                   valid_loader, n_epochs):\n",
    "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        metric.reset()\n",
    "        for inputs, y_batch in train_loader:\n",
    "            model.train()\n",
    "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(**inputs)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            metric.update(y_pred, y_batch)\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        history[\"train_losses\"].append(mean_loss)\n",
    "        history[\"train_metrics\"].append(metric.compute().item())\n",
    "        history[\"valid_metrics\"].append(\n",
    "            evaluate_named(model, valid_loader, metric).item())\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
    "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
    "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
    "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
    "    return history\n",
    "\n",
    "torch.manual_seed(42)\n",
    "learning_rate = 0.01\n",
    "model = WideAndDeepV3(n_features).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()\n",
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "history = train_named(model, optimizer, mse, rmse, train_loader_named,\n",
    "                      valid_loader_named, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models with Multiple Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepV4(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.deep_stack = nn.Sequential(\n",
    "            nn.Linear(n_features - 2, 50), nn.ReLU(),\n",
    "            nn.Linear(50, 40), nn.ReLU(),\n",
    "            nn.Linear(40, 30), nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(30 + 5, 1)\n",
    "        self.aux_output_layer = nn.Linear(30, 1)\n",
    "\n",
    "    def forward(self, X_wide, X_deep):\n",
    "        deep_output = self.deep_stack(X_deep)\n",
    "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
    "        main_output = self.output_layer(wide_and_deep)\n",
    "        aux_output = self.aux_output_layer(deep_output)\n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 1.0693, train metric: 0.9506, valid metric: 0.7085\n",
      "Epoch 2/20, train loss: 0.5817, train metric: 0.6946, valid metric: 0.6607\n",
      "Epoch 3/20, train loss: 0.5010, train metric: 0.6581, valid metric: 0.6425\n",
      "Epoch 4/20, train loss: 0.4690, train metric: 0.6497, valid metric: 0.6654\n",
      "Epoch 5/20, train loss: 0.4503, train metric: 0.6420, valid metric: 0.6338\n",
      "Epoch 6/20, train loss: 0.4387, train metric: 0.6373, valid metric: 0.6563\n",
      "Epoch 7/20, train loss: 0.4315, train metric: 0.6330, valid metric: 0.6193\n",
      "Epoch 8/20, train loss: 0.4249, train metric: 0.6302, valid metric: 0.6167\n",
      "Epoch 9/20, train loss: 0.4116, train metric: 0.6202, valid metric: 0.6450\n",
      "Epoch 10/20, train loss: 0.4085, train metric: 0.6198, valid metric: 0.5938\n",
      "Epoch 11/20, train loss: 0.4073, train metric: 0.6197, valid metric: 0.5959\n",
      "Epoch 12/20, train loss: 0.3914, train metric: 0.6078, valid metric: 0.6073\n",
      "Epoch 13/20, train loss: 0.3847, train metric: 0.6033, valid metric: 0.5815\n",
      "Epoch 14/20, train loss: 0.3849, train metric: 0.6048, valid metric: 0.6042\n",
      "Epoch 15/20, train loss: 0.3744, train metric: 0.5965, valid metric: 0.5740\n",
      "Epoch 16/20, train loss: 0.3690, train metric: 0.5928, valid metric: 0.6111\n",
      "Epoch 17/20, train loss: 0.3675, train metric: 0.5923, valid metric: 0.5766\n",
      "Epoch 18/20, train loss: 0.3606, train metric: 0.5869, valid metric: 0.5782\n",
      "Epoch 19/20, train loss: 0.3604, train metric: 0.5867, valid metric: 0.5664\n",
      "Epoch 20/20, train loss: 0.3566, train metric: 0.5837, valid metric: 0.5654\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "\n",
    "def evaluate_multi_out(model, data_loader, metric):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    with torch.no_grad():\n",
    "        for inputs, y_batch in data_loader:\n",
    "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred, _ = model(**inputs)\n",
    "            metric.update(y_pred, y_batch)\n",
    "    return metric.compute()\n",
    "\n",
    "def train_multi_out(model, optimizer, criterion, metric, train_loader,\n",
    "                   valid_loader, n_epochs):\n",
    "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        metric.reset()\n",
    "        for inputs, y_batch in train_loader:\n",
    "            model.train()\n",
    "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred, y_pred_aux = model(**inputs)\n",
    "            main_loss = criterion(y_pred, y_batch)\n",
    "            aux_loss = criterion(y_pred_aux, y_batch)\n",
    "            loss = 0.8 * main_loss + 0.2 * aux_loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            metric.update(y_pred, y_batch)\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        history[\"train_losses\"].append(mean_loss)\n",
    "        history[\"train_metrics\"].append(metric.compute().item())\n",
    "        history[\"valid_metrics\"].append(\n",
    "            evaluate_multi_out(model, valid_loader, metric).item())\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
    "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
    "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
    "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
    "    return history\n",
    "\n",
    "torch.manual_seed(42)\n",
    "learning_rate = 0.01\n",
    "model = WideAndDeepV4(n_features).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()\n",
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "history = train_multi_out(model, optimizer, mse, rmse, train_loader_named,\n",
    "                          valid_loader_named, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Image Classifier with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TorchVision to Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:02<00:00, 10.3MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 178kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.26MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 25.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms.v2 as T\n",
    "\n",
    "toTensor = T.Compose([T.ToImage(), T.ToDtype(torch.float32, scale=True)])\n",
    "\n",
    "train_and_valid_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"datasets\", train=True, download=True, transform=toTensor)\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"datasets\", train=False, download=True, transform=toTensor)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_data, valid_data = torch.utils.data.random_split(\n",
    "    train_and_valid_data, [55_000, 5_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry is a tuple (image, target):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample, y_sample = train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image has a shape \\[channels, rows, columns\\]. Grayscale images like in Fashion MNIST have a single channel (while RGB images have 3, and other types of images, such as satellite images, may have many more). Fashion images are grayscale and 28x28 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_valid_data.classes[y_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden1, n_hidden2, n_classes):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(n_inputs, n_hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden1, n_hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden2, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.mlp(X)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=300, n_hidden2=100,\n",
    "                        n_classes=10).to(device)\n",
    "xentropy = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 0.6058, train metric: 0.7816, valid metric: 0.8416\n",
      "Epoch 2/20, train loss: 0.4059, train metric: 0.8497, valid metric: 0.8372\n",
      "Epoch 3/20, train loss: 0.3633, train metric: 0.8663, valid metric: 0.8530\n",
      "Epoch 4/20, train loss: 0.3359, train metric: 0.8762, valid metric: 0.8660\n",
      "Epoch 5/20, train loss: 0.3147, train metric: 0.8835, valid metric: 0.8754\n",
      "Epoch 6/20, train loss: 0.2991, train metric: 0.8881, valid metric: 0.8666\n",
      "Epoch 7/20, train loss: 0.2859, train metric: 0.8916, valid metric: 0.8622\n",
      "Epoch 8/20, train loss: 0.2745, train metric: 0.8971, valid metric: 0.8722\n",
      "Epoch 9/20, train loss: 0.2639, train metric: 0.9007, valid metric: 0.8834\n",
      "Epoch 10/20, train loss: 0.2531, train metric: 0.9041, valid metric: 0.8810\n",
      "Epoch 11/20, train loss: 0.2463, train metric: 0.9068, valid metric: 0.8850\n",
      "Epoch 12/20, train loss: 0.2353, train metric: 0.9109, valid metric: 0.8910\n",
      "Epoch 13/20, train loss: 0.2303, train metric: 0.9125, valid metric: 0.8870\n",
      "Epoch 14/20, train loss: 0.2235, train metric: 0.9144, valid metric: 0.8734\n",
      "Epoch 15/20, train loss: 0.2154, train metric: 0.9184, valid metric: 0.8788\n",
      "Epoch 16/20, train loss: 0.2089, train metric: 0.9207, valid metric: 0.8826\n",
      "Epoch 17/20, train loss: 0.2030, train metric: 0.9234, valid metric: 0.8906\n",
      "Epoch 18/20, train loss: 0.1989, train metric: 0.9242, valid metric: 0.8884\n",
      "Epoch 19/20, train loss: 0.1924, train metric: 0.9271, valid metric: 0.8818\n",
      "Epoch 20/20, train loss: 0.1888, train metric: 0.9282, valid metric: 0.8716\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "_ = train2(model, optimizer, xentropy, accuracy, train_loader, valid_loader,\n",
    "           n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 4, 2], device='cuda:0')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "X_new, y_new = next(iter(valid_loader))\n",
    "X_new = X_new[:3].to(device)\n",
    "with torch.no_grad():\n",
    "    y_pred_logits = model(X_new)\n",
    "y_pred = y_pred_logits.argmax(dim=1)  # index of the largest logit\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sneaker', 'Coat', 'Pullover']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[train_and_valid_data.classes[index] for index in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whether the model made the correct predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 4, 2])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All correct! 😃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0010, 0.0000, 0.9110, 0.0000,\n",
       "         0.0880],\n",
       "        [0.0000, 0.0000, 0.0040, 0.0000, 0.9960, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.6250, 0.0000, 0.3350, 0.0000, 0.0390, 0.0000, 0.0000,\n",
       "         0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "y_proba = F.softmax(y_pred_logits, dim=1)\n",
    "if device == \"mps\":\n",
    "    y_proba = y_proba.cpu()\n",
    "y_proba.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9110, 0.0880, 0.0010, 0.0000],\n",
       "        [0.9960, 0.0040, 0.0000, 0.0000],\n",
       "        [0.6250, 0.3350, 0.0390, 0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_top4_values, y_top4_indices = torch.topk(y_pred_logits, k=4, dim=1)\n",
    "y_top4_probas = F.softmax(y_top4_values, dim=1)\n",
    "if device == \"mps\":\n",
    "    y_top4_probas = y_top4_probas.cpu()\n",
    "y_top4_probas.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 9, 5, 8],\n",
       "        [4, 2, 6, 0],\n",
       "        [2, 4, 6, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_top4_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266610"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([param.numel() for param in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    n_hidden = trial.suggest_int(\"n_hidden\", 20, 300)\n",
    "    model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=n_hidden,\n",
    "                            n_hidden2=n_hidden, n_classes=10).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    xentropy = nn.CrossEntropyLoss()\n",
    "    accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "    accuracy = accuracy.to(device)\n",
    "    history = train2(model, optimizer, xentropy, accuracy, train_loader,\n",
    "                     valid_loader, n_epochs=10)\n",
    "    validation_accuracy = max(history[\"valid_metrics\"])\n",
    "    return validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:20:53,727] A new study created in memory with name: no-name-27fd1323-5c92-43f9-8071-fa800aebc54b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, train loss: 2.2769, train metric: 0.1471, valid metric: 0.1860\n",
      "Epoch 2/10, train loss: 2.2093, train metric: 0.2794, valid metric: 0.3500\n",
      "Epoch 3/10, train loss: 2.1164, train metric: 0.4110, valid metric: 0.4554\n",
      "Epoch 4/10, train loss: 1.9776, train metric: 0.5137, valid metric: 0.5562\n",
      "Epoch 5/10, train loss: 1.7867, train metric: 0.5826, valid metric: 0.6026\n",
      "Epoch 6/10, train loss: 1.5775, train metric: 0.6184, valid metric: 0.6228\n",
      "Epoch 7/10, train loss: 1.3978, train metric: 0.6288, valid metric: 0.6326\n",
      "Epoch 8/10, train loss: 1.2605, train metric: 0.6360, valid metric: 0.6372\n",
      "Epoch 9/10, train loss: 1.1572, train metric: 0.6468, valid metric: 0.6424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:23:25,327] Trial 0 finished with value: 0.6435999870300293 and parameters: {'learning_rate': 0.00031489116479568613, 'n_hidden': 287}. Best is trial 0 with value: 0.6435999870300293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, train loss: 1.0782, train metric: 0.6537, valid metric: 0.6436\n",
      "Epoch 1/10, train loss: 1.1459, train metric: 0.6229, valid metric: 0.7338\n",
      "Epoch 2/10, train loss: 0.6108, train metric: 0.7841, valid metric: 0.7992\n",
      "Epoch 3/10, train loss: 0.5203, train metric: 0.8169, valid metric: 0.8094\n",
      "Epoch 4/10, train loss: 0.4810, train metric: 0.8302, valid metric: 0.8310\n",
      "Epoch 5/10, train loss: 0.4557, train metric: 0.8404, valid metric: 0.8352\n",
      "Epoch 6/10, train loss: 0.4387, train metric: 0.8460, valid metric: 0.8442\n",
      "Epoch 7/10, train loss: 0.4240, train metric: 0.8512, valid metric: 0.8408\n",
      "Epoch 8/10, train loss: 0.4123, train metric: 0.8566, valid metric: 0.8514\n",
      "Epoch 9/10, train loss: 0.3998, train metric: 0.8601, valid metric: 0.8532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:25:57,218] Trial 1 finished with value: 0.8547999858856201 and parameters: {'learning_rate': 0.008471801418819975, 'n_hidden': 188}. Best is trial 1 with value: 0.8547999858856201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, train loss: 0.3897, train metric: 0.8638, valid metric: 0.8548\n",
      "Epoch 1/10, train loss: 2.3069, train metric: 0.1144, valid metric: 0.1082\n",
      "Epoch 2/10, train loss: 2.2993, train metric: 0.1231, valid metric: 0.1294\n",
      "Epoch 3/10, train loss: 2.2914, train metric: 0.1606, valid metric: 0.1710\n",
      "Epoch 4/10, train loss: 2.2836, train metric: 0.1839, valid metric: 0.1840\n",
      "Epoch 5/10, train loss: 2.2762, train metric: 0.1891, valid metric: 0.1856\n",
      "Epoch 6/10, train loss: 2.2692, train metric: 0.1910, valid metric: 0.1898\n",
      "Epoch 7/10, train loss: 2.2623, train metric: 0.1933, valid metric: 0.1932\n",
      "Epoch 8/10, train loss: 2.2554, train metric: 0.2000, valid metric: 0.2022\n",
      "Epoch 9/10, train loss: 2.2485, train metric: 0.2122, valid metric: 0.2160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:28:28,531] Trial 2 finished with value: 0.23340000212192535 and parameters: {'learning_rate': 4.207988669606632e-05, 'n_hidden': 63}. Best is trial 1 with value: 0.8547999858856201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, train loss: 2.2414, train metric: 0.2299, valid metric: 0.2334\n",
      "Epoch 1/10, train loss: 2.3035, train metric: 0.1373, valid metric: 0.1526\n",
      "Epoch 2/10, train loss: 2.3005, train metric: 0.1569, valid metric: 0.1724\n",
      "Epoch 3/10, train loss: 2.2975, train metric: 0.1755, valid metric: 0.1896\n",
      "Epoch 4/10, train loss: 2.2945, train metric: 0.1941, valid metric: 0.2132\n",
      "Epoch 5/10, train loss: 2.2914, train metric: 0.2105, valid metric: 0.2288\n",
      "Epoch 6/10, train loss: 2.2884, train metric: 0.2261, valid metric: 0.2418\n",
      "Epoch 7/10, train loss: 2.2853, train metric: 0.2419, valid metric: 0.2580\n",
      "Epoch 8/10, train loss: 2.2823, train metric: 0.2581, valid metric: 0.2742\n",
      "Epoch 9/10, train loss: 2.2792, train metric: 0.2736, valid metric: 0.2918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:30:58,822] Trial 3 finished with value: 0.30959999561309814 and parameters: {'learning_rate': 1.7073967431528103e-05, 'n_hidden': 263}. Best is trial 1 with value: 0.8547999858856201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, train loss: 2.2761, train metric: 0.2897, valid metric: 0.3096\n",
      "Epoch 1/10, train loss: 1.8379, train metric: 0.4869, valid metric: 0.6208\n",
      "Epoch 2/10, train loss: 0.9751, train metric: 0.6666, valid metric: 0.6978\n",
      "Epoch 3/10, train loss: 0.7608, train metric: 0.7253, valid metric: 0.7416\n",
      "Epoch 4/10, train loss: 0.6704, train metric: 0.7639, valid metric: 0.7720\n",
      "Epoch 5/10, train loss: 0.6108, train metric: 0.7913, valid metric: 0.7906\n",
      "Epoch 6/10, train loss: 0.5687, train metric: 0.8053, valid metric: 0.8050\n",
      "Epoch 7/10, train loss: 0.5386, train metric: 0.8164, valid metric: 0.8082\n",
      "Epoch 8/10, train loss: 0.5158, train metric: 0.8243, valid metric: 0.8214\n",
      "Epoch 9/10, train loss: 0.4988, train metric: 0.8279, valid metric: 0.8220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:33:29,943] Trial 4 finished with value: 0.8220000267028809 and parameters: {'learning_rate': 0.002537815508265664, 'n_hidden': 218}. Best is trial 1 with value: 0.8547999858856201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, train loss: 0.4842, train metric: 0.8330, valid metric: 0.8092\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.008471801418819975, 'n_hidden': 188}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8547999858856201"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, train_loader, valid_loader):\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    n_hidden = trial.suggest_int(\"n_hidden\", 20, 300)\n",
    "    model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=n_hidden,\n",
    "                            n_hidden2=n_hidden, n_classes=10).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    xentropy = nn.CrossEntropyLoss()\n",
    "    accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "    accuracy = accuracy.to(device)\n",
    "    best_validation_accuracy = 0.0\n",
    "    for epoch in range(n_epochs):\n",
    "        history = train2(model, optimizer, xentropy, accuracy, train_loader,\n",
    "                         valid_loader, n_epochs=1)\n",
    "        validation_accuracy = max(history[\"valid_metrics\"])\n",
    "        if validation_accuracy > best_validation_accuracy:\n",
    "            best_validation_accuracy = validation_accuracy\n",
    "        trial.report(validation_accuracy, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    return best_validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_with_data = lambda trial: objective(\n",
    "    trial, train_loader=train_loader, valid_loader=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "objective_with_data = partial(objective, train_loader=train_loader,\n",
    "                              valid_loader=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:33:29,993] A new study created in memory with name: no-name-38c4ab57-e010-4c31-b3e6-9cf84c20adce\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 2.2769, train metric: 0.1471, valid metric: 0.1860\n",
      "Epoch 1/1, train loss: 2.2093, train metric: 0.2794, valid metric: 0.3500\n",
      "Epoch 1/1, train loss: 2.1164, train metric: 0.4110, valid metric: 0.4554\n",
      "Epoch 1/1, train loss: 1.9776, train metric: 0.5137, valid metric: 0.5562\n",
      "Epoch 1/1, train loss: 1.7867, train metric: 0.5826, valid metric: 0.6026\n",
      "Epoch 1/1, train loss: 1.5775, train metric: 0.6184, valid metric: 0.6228\n",
      "Epoch 1/1, train loss: 1.3978, train metric: 0.6288, valid metric: 0.6326\n",
      "Epoch 1/1, train loss: 1.2605, train metric: 0.6360, valid metric: 0.6372\n",
      "Epoch 1/1, train loss: 1.1572, train metric: 0.6468, valid metric: 0.6424\n",
      "Epoch 1/1, train loss: 1.0782, train metric: 0.6537, valid metric: 0.6436\n",
      "Epoch 1/1, train loss: 1.0162, train metric: 0.6611, valid metric: 0.6530\n",
      "Epoch 1/1, train loss: 0.9665, train metric: 0.6689, valid metric: 0.6620\n",
      "Epoch 1/1, train loss: 0.9258, train metric: 0.6761, valid metric: 0.6700\n",
      "Epoch 1/1, train loss: 0.8919, train metric: 0.6835, valid metric: 0.6782\n",
      "Epoch 1/1, train loss: 0.8629, train metric: 0.6897, valid metric: 0.6848\n",
      "Epoch 1/1, train loss: 0.8381, train metric: 0.6954, valid metric: 0.6876\n",
      "Epoch 1/1, train loss: 0.8166, train metric: 0.7009, valid metric: 0.6932\n",
      "Epoch 1/1, train loss: 0.7974, train metric: 0.7073, valid metric: 0.6964\n",
      "Epoch 1/1, train loss: 0.7802, train metric: 0.7119, valid metric: 0.7090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:38:38,280] Trial 0 finished with value: 0.7089999914169312 and parameters: {'learning_rate': 0.00031489116479568613, 'n_hidden': 287}. Best is trial 0 with value: 0.7089999914169312.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 0.7647, train metric: 0.7196, valid metric: 0.7082\n",
      "Epoch 1/1, train loss: 1.1485, train metric: 0.6157, valid metric: 0.7332\n",
      "Epoch 1/1, train loss: 0.6133, train metric: 0.7864, valid metric: 0.8082\n",
      "Epoch 1/1, train loss: 0.5200, train metric: 0.8179, valid metric: 0.8136\n",
      "Epoch 1/1, train loss: 0.4783, train metric: 0.8311, valid metric: 0.8232\n",
      "Epoch 1/1, train loss: 0.4533, train metric: 0.8402, valid metric: 0.8020\n",
      "Epoch 1/1, train loss: 0.4357, train metric: 0.8465, valid metric: 0.8446\n",
      "Epoch 1/1, train loss: 0.4211, train metric: 0.8510, valid metric: 0.8276\n",
      "Epoch 1/1, train loss: 0.4083, train metric: 0.8562, valid metric: 0.8398\n",
      "Epoch 1/1, train loss: 0.3981, train metric: 0.8606, valid metric: 0.8532\n",
      "Epoch 1/1, train loss: 0.3881, train metric: 0.8640, valid metric: 0.8582\n",
      "Epoch 1/1, train loss: 0.3782, train metric: 0.8663, valid metric: 0.8532\n",
      "Epoch 1/1, train loss: 0.3699, train metric: 0.8693, valid metric: 0.8566\n",
      "Epoch 1/1, train loss: 0.3631, train metric: 0.8712, valid metric: 0.8574\n",
      "<<204 more lines>>\n",
      "Epoch 1/1, train loss: 0.2761, train metric: 0.8982, valid metric: 0.8792\n",
      "Epoch 1/1, train loss: 0.2684, train metric: 0.9003, valid metric: 0.8848\n",
      "Epoch 1/1, train loss: 0.2615, train metric: 0.9045, valid metric: 0.8772\n",
      "Epoch 1/1, train loss: 0.2560, train metric: 0.9049, valid metric: 0.8820\n",
      "Epoch 1/1, train loss: 0.2497, train metric: 0.9071, valid metric: 0.8832\n",
      "Epoch 1/1, train loss: 0.2434, train metric: 0.9097, valid metric: 0.8848\n",
      "Epoch 1/1, train loss: 0.2380, train metric: 0.9126, valid metric: 0.8832\n",
      "Epoch 1/1, train loss: 0.2331, train metric: 0.9145, valid metric: 0.8806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 08:32:19,547] Trial 16 finished with value: 0.8848000168800354 and parameters: {'learning_rate': 0.032666299131732864, 'n_hidden': 142}. Best is trial 12 with value: 0.8867999911308289.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 0.2271, train metric: 0.9154, valid metric: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 08:32:35,221] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 1.5604, train metric: 0.5038, valid metric: 0.6536\n",
      "Epoch 1/1, train loss: 0.6189, train metric: 0.7751, valid metric: 0.8314\n",
      "Epoch 1/1, train loss: 0.4237, train metric: 0.8447, valid metric: 0.8492\n",
      "Epoch 1/1, train loss: 0.3814, train metric: 0.8605, valid metric: 0.8582\n",
      "Epoch 1/1, train loss: 0.3567, train metric: 0.8681, valid metric: 0.8622\n",
      "Epoch 1/1, train loss: 0.3375, train metric: 0.8744, valid metric: 0.8674\n",
      "Epoch 1/1, train loss: 0.3246, train metric: 0.8788, valid metric: 0.8480\n",
      "Epoch 1/1, train loss: 0.3123, train metric: 0.8849, valid metric: 0.8644\n",
      "Epoch 1/1, train loss: 0.3012, train metric: 0.8871, valid metric: 0.8734\n",
      "Epoch 1/1, train loss: 0.2915, train metric: 0.8916, valid metric: 0.8760\n",
      "Epoch 1/1, train loss: 0.2858, train metric: 0.8931, valid metric: 0.8758\n",
      "Epoch 1/1, train loss: 0.2778, train metric: 0.8955, valid metric: 0.8804\n",
      "Epoch 1/1, train loss: 0.2715, train metric: 0.8972, valid metric: 0.8616\n",
      "Epoch 1/1, train loss: 0.2642, train metric: 0.9011, valid metric: 0.8800\n",
      "Epoch 1/1, train loss: 0.2598, train metric: 0.9009, valid metric: 0.8782\n",
      "Epoch 1/1, train loss: 0.2561, train metric: 0.9033, valid metric: 0.8734\n",
      "Epoch 1/1, train loss: 0.2494, train metric: 0.9058, valid metric: 0.8788\n",
      "Epoch 1/1, train loss: 0.2474, train metric: 0.9069, valid metric: 0.8720\n",
      "Epoch 1/1, train loss: 0.2411, train metric: 0.9089, valid metric: 0.8750\n",
      "Epoch 1/1, train loss: 0.2375, train metric: 0.9103, valid metric: 0.8768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 08:37:45,329] Trial 18 finished with value: 0.8830000162124634 and parameters: {'learning_rate': 0.0954812841907134, 'n_hidden': 50}. Best is trial 12 with value: 0.8867999911308289.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 0.2353, train metric: 0.9109, valid metric: 0.8830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 08:38:00,038] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 0.7417, train metric: 0.7395, valid metric: 0.7640\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler,\n",
    "                            pruner=pruner)\n",
    "study.optimize(objective_with_data, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8867999911308289"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.08525846269447772, 'n_hidden': 116}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading a PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"my_fashion_mnist.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load(\"my_fashion_mnist.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.eval()\n",
    "y_pred_logits = loaded_model(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"my_fashion_mnist_weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (mlp): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=300, n_hidden2=100,\n",
    "                            n_classes=10)\n",
    "loaded_weights = torch.load(\"my_fashion_mnist_weights.pt\", weights_only=True)\n",
    "new_model.load_state_dict(loaded_weights)\n",
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = {\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"model_hyperparameters\": {\n",
    "        \"n_inputs\": 1 * 28 * 28,\n",
    "        \"n_hidden1\": 300,\n",
    "        \"n_hidden2\": 100,\n",
    "        \"n_classes\": 10,\n",
    "    }\n",
    "}\n",
    "torch.save(model_data, \"my_fashion_mnist_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (mlp): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data = torch.load(\"my_fashion_mnist_model.pt\", weights_only=True)\n",
    "new_model = ImageClassifier(**loaded_data[\"model_hyperparameters\"])\n",
    "new_model.load_state_dict(loaded_data[\"model_state_dict\"])\n",
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling and Optimizing a PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchscript_model = torch.jit.trace(model, X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchscript_model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_model = torch.jit.optimize_for_inference(torchscript_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_model.save(\"my_fashion_mnist_torchscript.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_torchscript_model = torch.jit.load(\"my_fashion_mnist_torchscript.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -3.3324,  -0.7572,  -4.1671,  -1.9444,  -1.6955,   2.0123,  -3.2624,\n",
       "           8.6379,  -0.5685,   6.2972],\n",
       "        [ -0.1434,  -3.8626,  11.8279,  -0.3164,  17.3995, -13.1888,   7.8158,\n",
       "         -11.8338,  -1.4709,  -7.9412],\n",
       "        [  0.3996,  -2.5537,   7.5992,   0.1775,   6.9748,  -6.1942,   4.8270,\n",
       "          -5.8584,  -1.4327,  -4.3257]], device='cuda:0')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_logits = loaded_torchscript_model(X_new)\n",
    "y_pred_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1007 08:38:10.662000 360 torch/_inductor/utils.py:1436] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    }
   ],
   "source": [
    "if device == \"cuda\":\n",
    "    y_pred_logits = compiled_model(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises 1. to 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PyTorch is similar to NumPy is many ways, but it offers some extra features. The main ones are:\n",
    "    * Auto-differentiation\n",
    "    * Support for hardware accelerators\n",
    "    * Includes optimizers and ready-to-use neural net components\n",
    "\n",
    "2. `torch.exp()` returns a copy of the input tensor while `torch.exp_()` modifies it in place. Similarly, `torch.relu()` returns a copy while `torch.relu_()` modifies in place.\n",
    "\n",
    "3. To create a new tensor on the GPU, you can use one of the following methods:\n",
    "     * Set the `device` argument when calling `torch.tensor()`, `torch.rand()`, or other functions that create new tensors. For example, `torch.randn(10, device=\"cuda\")` creates a new tensor on the CUDA GPU, with 10 random elements.\n",
    "     * Create a new tensor on the CPU, then transfer it to the GPU by using calling its `to()` method, for example `torch.randn(10).to(\"cuda\")`. However, it's more efficient to create the tensor directly on the GPU.\n",
    "     * The `*_like()` functions such as `ones_like()` and `zeros_like()` create a new tensor on the same device as another tensor. They also use the same data type.\n",
    "    * Lastly, if you execute an operation on a tensor that lives on the GPU, the result will generally be a new tensor on the GPU (unless you use an in-place operation such as `torch.exp_()`.\n",
    "\n",
    "4. Here are three ways to perform tensor computations without using autograd:\n",
    "    * Manipulate tensors created with `requires_grad=False` (which is the default).\n",
    "    * Run the computations inside a `with torch.no_grad():` block.\n",
    "    * Call the `detach()` method on the tensor you want to manipulate without autograd.\n",
    "\n",
    "5. Here's what happens in each case:\n",
    "    * The first code sample will work fine, it will _not_ cause a `RuntimeError`: indeed, the `cos()` method creates a new (non-leaf) tensor, then `exp_()` modifies it in place. During the backward pass, PyTorch is able to backpropagate through the `exp_()` operation because the derivative of exp(x) is exp(x), so PyTorch doesn't need to know what the input x was, it can just use the output of the forward pass (i.e., exp(x)) during the backward pass.\n",
    "    * If you replace `z = t.cos().exp_()` with `z = t.cos_().exp()` then you will get a `RuntimeError` on that line (\"_a leaf Variable that requires grad is being used in an in-place operation_\"). Indeed, `t` is a leaf tensor (since it was created directly by the user, not the result of any computation) and you cannot apply an in-place operation on a leaf tensor with `requires_grad=True`.\n",
    "    * If you replace `z = t.cos().exp_()` with `z = t.exp().cos_()`, then you will get a `RuntimeError` (\"_one of the variables needed for gradient computation has been modified by an inplace operation_\") during the backward pass. Indeed, the `exp()` operation relies on the fact that the derivative of exp(_t_) is exp(_t_), so it doesn't need to store the tensor `t` for the backward pass, instead it relies on the fact that it can just use the tensor returned by `t.exp()` (let's call it `e`). So far so good. But when we call the `cos_()` operation, it knows that it will need its input during the backward pass (since the derivative of cos(_e_) is –sin(_e_)), so it keeps a copy of its input tensor `e`. Next, it tries to modify the original `e` in-place, and in doing so it notices that this tensor is needed by another operation (`exp()`) for the backward pass, so it knows that something is fishy and it raises a `RuntimeError`.\n",
    "    * The second code example will fail during backpropogation, with a `RuntimeError`. It's a very similar error to the previous one: the `cos()` operation stores a reference to its input tensor `v`, since `v` will be needed during the backward pass. Indeed, the derivative of cos(_v_) is –sin(_v_), so we need to save _v_. Next, the `sin_()` operation creates a copy of its input `v` (since it's an in-place operation, it knows that it must create a copy, not just preserve a reference) then it proceeds to modify the original `v`, but this tensor is needed to compute the gradient of `cos(_v_)`, so PyTorch raises a `RuntimeError`.\n",
    "    * If you replace `w = v.cos() * v.sin_()` with `w = v.cos_() * v.sin()`, then there is no longer any `RuntimeError`. Indeed, the `cos_()` operation creates a copy of its input `v` so it can compute –sin(_v_) during the backward pass. The `sin()` operation is not in-place so in keeps a reference to its input `v`, not a copy. Backprop then runs just fine. However, there's a catch: by the time the `sin()` operation runs, its input `v` is no longer equal to 3.0, but instead it's equal to cos(3.0) since the `cos_()` modified `v` in place. As a result, `w = v.cos() * v.sin_()` does _not_ give the same result as `w = v.cos_() * v.sin()`. The former computes cos(3) * sin(3) while the latter computes cos(3) * sin(cos(3)). And of course the gradients change as well. That's why you should be very careful with in-place operations: they can make your code faster, sure, but they can also make it silently wrong.\n",
    "\n",
    "6. A `Linear(100, 200)` module has 200 neurons: one per output. Its `weight` tensor has a shape of [200, 100] and its `bias` parameter has a shape of [200]. It expects its inputs to have a shape of [..., 100], for example [32, 100], or [32, 64, 100]. It treats all dimensions independently, except for the last one. The output shape is identical to the input shape, except that the last dimension is replaced with 200. For example, if the input shape is [32, 64, 100], then the output shape is [32, 64, 200].\n",
    "\n",
    "7. The main steps of a PyTorch training loop are:\n",
    "    * Prepare a batch of samples from the training set. You can use a `DataLoader` for this.\n",
    "    * Optionally transfer these samples to the GPU (typically using `X_batch.to(device)` and `y_batch.to(device)`).\n",
    "    * Run the inputs through the model, for example `y_pred = model(X_batch)`.\n",
    "    * Compute the loss, for example `loss = criterion(y_pred, y_true)`.\n",
    "    * Backpropagate through the loss using `loss.backward()`.\n",
    "    * Perform an optimizer step: `optimizer.step()`.\n",
    "    * Zero out the gradients: `optimizer.zero_grad()` (alternatively, you can do this before the backward pass, which may be safer if the gradients are non-zero before the training loop starts).\n",
    "    * The whole training loop is often split into epochs, but this is optional.\n",
    "\n",
    "8. It is recommended to create the optimizer _after_ the model is moved to the GPU because most optimizers have some internal state, and this state is usually allocated on the same device as the model parameters.\n",
    "\n",
    "9. To speed up training when using a GPU, you should generally set the following `DataLoader` options:\n",
    "    * Set the data loader's `num_workers` argument to the number of processes you want to use for data loading and preprocessing. This will often speed up training by pre-fetching the next batches on the CPU while the GPU is still working on the current batch. The optimal number depends on your platform, hardware, and workload, so you should experiment with different values.\n",
    "    * Set the data loader's `prefetch_factor` argument to control the number of batches that each worker pre-fetches.\n",
    "    * If spawning and synchronizing workers causes too much overhead (especially on Windows), you can try setting `persistent_workers=True` to reuse the same workers across epochs.\n",
    "\n",
    "10. The main classification losses provided by PyTorch are:\n",
    "    * `nn.CrossEntropyLoss`: this is generally the loss you want to use for multiclass classification, as it's efficient and numerically stable. This loss works directly on logits, not probabilities, so your model must not include the softmax activation function on the output layer. As a result, whenever you need to estimate probabilities, you must call the `F.softmax()` function on the logits output by the model.\n",
    "    * `nn.BCEWithLogitsLoss` (BCE stands for _binary cross-entropy_): this is usually the loss you want to use for binary classification, for the same reason as `nn.CrossEntropyLoss`. Just like the previous loss, it works directly with logits, so your model must not include the sigmoid activation function on the output layer. Whenever you need to estimate probabilities, you must call the `F.sigmoid()` function on the logits output by the model. Note that some people prefer to use `nn.CrossEntropyLoss` even for binary classification, as it makes the code more consistent regardless of the number of classes, at a tiny computational and memory cost.\n",
    "    * `nn.NLLLoss` (NLL stands for _negative log-likelihood_): this is an alternative to `nn.CrossEntropyLoss` for multiclass classification. To use it, your model must output log probabilities rather than logits. This can be done using `nn.LogSoftmax()` or `F.log_softmax()`. This approach is a bit slower than using `CrossEntropyLoss`, but it can be useful if you want your model to output log probabilities rather than logits, or when you wish to tweak the probability distribution before computing the final loss (indeed, it is sometimes easier to modify log probabilities rather than logits). Whenever you need to estimate probabilities, you must call `torch.exp()` on the model's outputs.\n",
    "    * `nn.BCELoss`: this loss is an alternative to `nn.BCEWithLogitsLoss` for binary classification. It assumes that your model outputs probabilities rather than logits, so your model's output layer must use the sigmoid activation function. This can be convenient if you want your model to output probabilities directly, but it's a bit slower and less numerically stable than using `BCEWithLogitsLoss`.\n",
    "\n",
    "11. Calling `model.train()` before training and `model.eval()` before evaluation is important because some layers (such as `nn.Dropout`, `nn.BatchNorm1d` or `nn.BatchNorm2d`) don't behave in the same way during training and evaluation, therefore we must tell the model in which mode it should run.\n",
    "\n",
    "12. Both `torch.jit.trace()` and `torch.jit.script()` attempt to capture your model's computation graph and turn it into TorchScript code that can be optimized, saved, and deployed to various platforms. However, these functions work very differently:\n",
    "    * The `torch.jit.trace()` function runs your model with a tracing tensor that captures which operations are executed. It's quite simple and works well for simple models, but it cannot capture conditionals (e.g., `if`, `elif`, `else`, `match`): it only captures the branch of the conditional that is actually executed during tracing. Similarly, if your model contains a loop (e.g., `for` or `while`) then tracing will not capture the loop itself, it will only capture the repeated operations.\n",
    "    * The`torch.jit.script()` function actually parses your Python code to generate TorchScript code. This allows it to detect conditionals (as long as the conditions are tensors), and also capture loops. However, it only works with a subset of Python: you cannot use global variables, Python generators (`yield`), complex list comprehensions, variable length function arguments (`*args` or `**kwargs`), or `match` statements. Moreover, types must be fixed (a function cannot return an integer in some cases and a float in others), and you can only call other functions if they also respect these rules, so no standard library, no third-party libraries, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: _Use autograd to find the gradient vector of f(_x_, _y_) = sin(_x_<sup>2</sup> _y_) at the point (_x_, _y_) = (1.2, 3.4)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.489864706993103, 0.26291730999946594)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x, y):\n",
    "    return torch.sin(x ** 2 * y)\n",
    "\n",
    "x = torch.tensor(1.2, requires_grad=True)\n",
    "y = torch.tensor(3.4, requires_grad=True)\n",
    "result = f(x, y)\n",
    "result.backward()\n",
    "\n",
    "x.grad.item(), y.grad.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could use a vectorized implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4899, 0.2629])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(v):\n",
    "    return torch.sin(v[0] ** 2 * v[1])\n",
    "\n",
    "v = torch.tensor([1.2, 3.4], requires_grad=True)\n",
    "result = f(v)\n",
    "result.backward()\n",
    "\n",
    "v.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the same partial derivatives, but this time they are wrapped in a gradient tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check this result by computing an approximation of the partial derivatives, using the fact that the partial derivative of a function $f(x, y)$ with regard to $x$, at a point $(x_0, y_0)$ is the limit of $\\dfrac{f(x_0 + \\epsilon, y_0) - f(x_0, y0)}{\\epsilon}$ as $\\epsilon$ approaches zero. Similarly, the partial derivative of that function with regard to $y$, at the same point $(x_0, y_0)$, is the limit of $\\dfrac{f(x_0, y_0 + \\epsilon) - f(x_0, y0)}{\\epsilon}$ as $\\epsilon$ approaches zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4901161193847656, 0.26226043701171875)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 0.00005\n",
    "df_dx = (f(x + eps, y) - f(x, y)) / eps\n",
    "df_dy = (f(x, y + eps) - f(x, y)) / eps\n",
    "\n",
    "df_dx.item(), df_dy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's close enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also derive the equations for the partial derivatives mathematically (see the [calculus tutorial](math_differential_calculus.ipynb) to learn how to do this):\n",
    "* $\\dfrac{\\partial f}{\\partial x} = 2xy \\cos(x^2 y)$\n",
    "* $\\dfrac{\\partial f}{\\partial y} = x^2 \\cos(x^2 y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4898648262023926, 0.26291730999946594)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dx = 2 * x * y * torch.cos(x**2 * y)\n",
    "df_dy = x ** 2 * torch.cos(x**2 * y)\n",
    "\n",
    "df_dx.item(), df_dy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: _Create a custom `Dense` module that replicates the functionality of an `nn.Linear` module followed by an `nn.ReLU` module. Try implementing it first using the `nn.Linear` and `nn.ReLU` modules, and then reimplement it using `nn.Parameter` and the `relu()` function._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.relu(self.linear(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "dense = Dense(3, 5)\n",
    "X = torch.randn(2, 3)\n",
    "y_pred = dense(X)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks fine. We can double-check that it gives the right result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_check = dense.relu(X @ dense.linear.weight.T + dense.linear.bias)\n",
    "torch.allclose(y_pred, y_pred_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. Now let's reimplement the `Dense` class using `nn.Parameter` and `relu()` instead of `nn.Linear` and `nn.ReLU`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense2(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "\n",
    "    def forward(self, X):\n",
    "        z = X @ self.weight.T + self.bias\n",
    "        return F.relu(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "dense2 = Dense2(3, 5)\n",
    "X = torch.randn(2, 3)\n",
    "y_pred2 = dense2(X)\n",
    "y_pred2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks fine. Again, we can double-check that it gives the right result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2_check = F.relu(X @ dense2.weight.T + dense2.bias)\n",
    "torch.allclose(y_pred2, y_pred2_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Chapter 11, we will see that it's preferable to initialize the weights using Kaiming initialization, when the activation function is ReLU, so let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense3(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        nn.init.kaiming_uniform_(self.weight, nonlinearity=\"relu\")\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "\n",
    "    def forward(self, X):\n",
    "        z = X @ self.weight.T + self.bias\n",
    "        return F.relu(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "dense3 = Dense3(3, 5)\n",
    "X = torch.randn(2, 3)\n",
    "y_pred3 = dense3(X)\n",
    "y_pred3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still works fine. Again, we can double-check that this module gives the right result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3_check = F.relu(X @ dense3.weight.T + dense3.bias)\n",
    "torch.allclose(y_pred3, y_pred3_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: _Build and train a classification MLP on the CoverType dataset._\n",
    "\n",
    "Step 1: _Load the dataset using `sklearn.datasets.fetch_covtype()` and create a custom PyTorch `Dataset` for this data._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: do not forget to scale the inputs, as gradient descent might not work well otherwise (as we saw in Chapter 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "covtype = fetch_covtype()\n",
    "\n",
    "X_covtype = torch.tensor(covtype.data, dtype=torch.float32)\n",
    "means = X_covtype.mean(dim=0, keepdim=True)\n",
    "stds = X_covtype.std(dim=0, keepdim=True)\n",
    "X_standardized_covtype = (X_covtype - means) / stds\n",
    "\n",
    "y_covtype = torch.tensor(covtype.target - 1, dtype=torch.long)\n",
    "\n",
    "covtype_dataset = TensorDataset(X_standardized_covtype, y_covtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the targets range from 1 to 7, but the `nn.CrossEntropyLoss` expects it to start at 0, which is why we subtract 1 from the targets. We also convert the inputs from 64-bit floats to 32-bit floats, and the targets to 64-bit integers. These are the default types in PyTorch for floats and integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([54]), torch.Size([]))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample0, target0 = covtype_dataset[0]\n",
    "sample0.shape, target0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: _Create data loaders for training, validation, and testing._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is not shuffled or split by default, so we shuffle and split it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_size = len(covtype_dataset) * 80 // 100\n",
    "valid_size = len(covtype_dataset) * 10 // 100\n",
    "test_size = len(covtype_dataset) - train_size - valid_size\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = random_split(\n",
    "    covtype_dataset,\n",
    "    [train_size, valid_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: _Build a custom MLP module to tackle this classification task. You can optionally use the custom `Dense` module from the previous exercise._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to do this. Let's look at a few alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're building an MLP, which is just a stack of layers, we can just use a `nn.Sequential` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = len(covtype.feature_names)  # == 54\n",
    "n_classes = len(set(covtype.target))  # == 7\n",
    "\n",
    "torch.manual_seed(42)\n",
    "covtype_model = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 200), nn.ReLU(),\n",
    "    nn.Linear(200, 100), nn.ReLU(),\n",
    "    nn.Linear(100, 50), nn.ReLU(),\n",
    "    nn.Linear(50, n_classes)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output layer must not use any activation function since we will use the `nn.CrossEntropyLoss`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use the `Dense3` class we defined earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "covtype_model = nn.Sequential(\n",
    "    Dense3(n_inputs, 200),\n",
    "    Dense3(200, 100),\n",
    "    Dense3(100, 50),\n",
    "    nn.Linear(50, n_classes)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can create a custom module. Let's make it flexible so it accepts a list containing the number of neurons in each hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoverTypeModel(nn.Module):\n",
    "    def __init__(self, n_neurons, n_inputs=n_inputs, n_classes=n_classes):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            Dense3(n_in, n_out)\n",
    "            for n_in, n_out in zip([n_inputs] + n_neurons, n_neurons)\n",
    "        ] + [nn.Linear(n_neurons[-1], n_classes)]\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.mlp(X)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "covtype_model = CoverTypeModel([200, 100, 50]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we could use a `nn.ModuleList` instead of a `nn.Sequential` module, and modify the `forward()` method to explicitly run each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoverTypeModel(nn.Module):\n",
    "    def __init__(self, n_neurons, n_inputs=n_inputs, n_classes=n_classes):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            Dense3(n_in, n_out)\n",
    "            for n_in, n_out in zip([n_inputs] + n_neurons, n_neurons)\n",
    "        ] + [nn.Linear(n_neurons[-1], n_classes)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: _Train this model on the GPU, and try to reach 93% accuracy on the test set. For this, you will likely have to perform hyperparameter search to find the right number of layers and neurons per layer, a good learning rate and batch size, and so on. You can optionally use Optuna for this._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model on the GPU. As we saw in Chapter 4, it's often helpful to reduce the learning rate at the end of training, so let's do that. We will train for 6 times 15 epochs, reducing the learning rate each time. The results might vary depending on the platform, but you should get over 94% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, train loss: 0.5831, train metric: 0.7497, valid metric: 0.7917\n",
      "Epoch 2/15, train loss: 0.4597, train metric: 0.8037, valid metric: 0.8138\n",
      "Epoch 3/15, train loss: 0.4057, train metric: 0.8284, valid metric: 0.8317\n",
      "Epoch 4/15, train loss: 0.3706, train metric: 0.8447, valid metric: 0.8384\n",
      "Epoch 5/15, train loss: 0.3447, train metric: 0.8568, valid metric: 0.8638\n",
      "Epoch 6/15, train loss: 0.3237, train metric: 0.8665, valid metric: 0.8642\n",
      "Epoch 7/15, train loss: 0.3078, train metric: 0.8735, valid metric: 0.8720\n",
      "Epoch 8/15, train loss: 0.2945, train metric: 0.8793, valid metric: 0.8845\n",
      "Epoch 9/15, train loss: 0.2830, train metric: 0.8839, valid metric: 0.8786\n",
      "Epoch 10/15, train loss: 0.2737, train metric: 0.8881, valid metric: 0.8675\n",
      "Epoch 11/15, train loss: 0.2654, train metric: 0.8916, valid metric: 0.8917\n",
      "Epoch 12/15, train loss: 0.2561, train metric: 0.8959, valid metric: 0.8846\n",
      "Epoch 13/15, train loss: 0.2513, train metric: 0.8982, valid metric: 0.8910\n",
      "Epoch 14/15, train loss: 0.2443, train metric: 0.9008, valid metric: 0.8954\n",
      "Epoch 15/15, train loss: 0.2380, train metric: 0.9037, valid metric: 0.8874\n",
      "Epoch 1/15, train loss: 0.1995, train metric: 0.9201, valid metric: 0.9124\n",
      "Epoch 2/15, train loss: 0.1946, train metric: 0.9223, valid metric: 0.9174\n",
      "Epoch 3/15, train loss: 0.1918, train metric: 0.9234, valid metric: 0.9155\n",
      "Epoch 4/15, train loss: 0.1892, train metric: 0.9241, valid metric: 0.9168\n",
      "Epoch 5/15, train loss: 0.1874, train metric: 0.9246, valid metric: 0.9207\n",
      "Epoch 6/15, train loss: 0.1853, train metric: 0.9260, valid metric: 0.9209\n",
      "Epoch 7/15, train loss: 0.1831, train metric: 0.9266, valid metric: 0.9191\n",
      "Epoch 8/15, train loss: 0.1817, train metric: 0.9270, valid metric: 0.9224\n",
      "Epoch 9/15, train loss: 0.1802, train metric: 0.9279, valid metric: 0.9237\n",
      "Epoch 10/15, train loss: 0.1784, train metric: 0.9283, valid metric: 0.9197\n",
      "Epoch 11/15, train loss: 0.1766, train metric: 0.9292, valid metric: 0.9195\n",
      "Epoch 12/15, train loss: 0.1753, train metric: 0.9297, valid metric: 0.9203\n",
      "Epoch 13/15, train loss: 0.1745, train metric: 0.9299, valid metric: 0.9193\n",
      "Epoch 14/15, train loss: 0.1724, train metric: 0.9309, valid metric: 0.9224\n",
      "Epoch 15/15, train loss: 0.1716, train metric: 0.9312, valid metric: 0.9253\n",
      "Epoch 1/15, train loss: 0.1480, train metric: 0.9415, valid metric: 0.9354\n",
      "Epoch 2/15, train loss: 0.1455, train metric: 0.9423, valid metric: 0.9318\n",
      "Epoch 3/15, train loss: 0.1443, train metric: 0.9432, valid metric: 0.9342\n",
      "Epoch 4/15, train loss: 0.1431, train metric: 0.9436, valid metric: 0.9350\n",
      "Epoch 5/15, train loss: 0.1425, train metric: 0.9436, valid metric: 0.9340\n",
      "<<20 more lines>>\n",
      "Epoch 11/15, train loss: 0.1171, train metric: 0.9544, valid metric: 0.9446\n",
      "Epoch 12/15, train loss: 0.1168, train metric: 0.9545, valid metric: 0.9446\n",
      "Epoch 13/15, train loss: 0.1162, train metric: 0.9544, valid metric: 0.9436\n",
      "Epoch 14/15, train loss: 0.1159, train metric: 0.9546, valid metric: 0.9446\n",
      "Epoch 15/15, train loss: 0.1156, train metric: 0.9546, valid metric: 0.9449\n",
      "Epoch 1/15, train loss: 0.1087, train metric: 0.9581, valid metric: 0.9470\n",
      "Epoch 2/15, train loss: 0.1081, train metric: 0.9586, valid metric: 0.9472\n",
      "Epoch 3/15, train loss: 0.1076, train metric: 0.9591, valid metric: 0.9466\n",
      "Epoch 4/15, train loss: 0.1073, train metric: 0.9588, valid metric: 0.9470\n",
      "Epoch 5/15, train loss: 0.1072, train metric: 0.9591, valid metric: 0.9477\n",
      "Epoch 6/15, train loss: 0.1068, train metric: 0.9591, valid metric: 0.9476\n",
      "Epoch 7/15, train loss: 0.1067, train metric: 0.9593, valid metric: 0.9466\n",
      "Epoch 8/15, train loss: 0.1063, train metric: 0.9594, valid metric: 0.9473\n",
      "Epoch 9/15, train loss: 0.1062, train metric: 0.9595, valid metric: 0.9468\n",
      "Epoch 10/15, train loss: 0.1058, train metric: 0.9596, valid metric: 0.9468\n",
      "Epoch 11/15, train loss: 0.1057, train metric: 0.9598, valid metric: 0.9481\n",
      "Epoch 12/15, train loss: 0.1056, train metric: 0.9598, valid metric: 0.9475\n",
      "Epoch 13/15, train loss: 0.1053, train metric: 0.9598, valid metric: 0.9466\n",
      "Epoch 14/15, train loss: 0.1050, train metric: 0.9598, valid metric: 0.9478\n",
      "Epoch 15/15, train loss: 0.1049, train metric: 0.9600, valid metric: 0.9473\n",
      "Epoch 1/15, train loss: 0.1014, train metric: 0.9616, valid metric: 0.9493\n",
      "Epoch 2/15, train loss: 0.1009, train metric: 0.9617, valid metric: 0.9488\n",
      "Epoch 3/15, train loss: 0.1008, train metric: 0.9620, valid metric: 0.9496\n",
      "Epoch 4/15, train loss: 0.1007, train metric: 0.9620, valid metric: 0.9485\n",
      "Epoch 5/15, train loss: 0.1006, train metric: 0.9620, valid metric: 0.9496\n",
      "Epoch 6/15, train loss: 0.1004, train metric: 0.9623, valid metric: 0.9495\n",
      "Epoch 7/15, train loss: 0.1003, train metric: 0.9622, valid metric: 0.9494\n",
      "Epoch 8/15, train loss: 0.1001, train metric: 0.9622, valid metric: 0.9492\n",
      "Epoch 9/15, train loss: 0.1001, train metric: 0.9622, valid metric: 0.9488\n",
      "Epoch 10/15, train loss: 0.0999, train metric: 0.9623, valid metric: 0.9495\n",
      "Epoch 11/15, train loss: 0.0998, train metric: 0.9625, valid metric: 0.9491\n",
      "Epoch 12/15, train loss: 0.0997, train metric: 0.9624, valid metric: 0.9494\n",
      "Epoch 13/15, train loss: 0.0996, train metric: 0.9623, valid metric: 0.9496\n",
      "Epoch 14/15, train loss: 0.0995, train metric: 0.9626, valid metric: 0.9501\n",
      "Epoch 15/15, train loss: 0.0993, train metric: 0.9626, valid metric: 0.9490\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "covtype_model = CoverTypeModel([200, 100, 50]).to(device)\n",
    "\n",
    "for learning_rate in [0.16, 0.08, 0.04, 0.02, 0.01, 0.005]:\n",
    "    n_epochs = 15\n",
    "    optimizer = torch.optim.SGD(covtype_model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    metric = torchmetrics.Accuracy(task=\"multiclass\",\n",
    "                                   num_classes=n_classes).to(device)\n",
    "    history = train2(covtype_model, optimizer, criterion, metric, train_loader,\n",
    "                     valid_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9488, device='cuda:0')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tm(covtype_model, test_loader, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I manually tuned the hyperparameters above through trial and error. It took about 30 minutes of search to achieve over 94% accuracy, so I didn’t need to run a full hyperparameter search. However, you can definitely use Optuna for this task if you want to get even better results. The code below tunes the learning rate, the number of hidden layers, and the number of neurons per hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 1.0, log=True)\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    n_hidden = trial.suggest_int(\"n_hidden\", 30, 150)\n",
    "    covtype_model = CoverTypeModel([n_hidden] * n_layers).to(device)\n",
    "    optimizer = torch.optim.SGD(covtype_model.parameters(), lr=learning_rate)\n",
    "    xentropy = nn.CrossEntropyLoss()\n",
    "    accuracy = torchmetrics.Accuracy(task=\"multiclass\",\n",
    "                                     num_classes=n_classes).to(device)\n",
    "    best_validation_accuracy = 0.0\n",
    "    for epoch in range(n_epochs):\n",
    "        history = train2(covtype_model, optimizer, xentropy, accuracy,\n",
    "                         train_loader, valid_loader, n_epochs=1)\n",
    "        validation_accuracy = max(history[\"valid_metrics\"])\n",
    "        if validation_accuracy > best_validation_accuracy:\n",
    "            best_validation_accuracy = validation_accuracy\n",
    "        trial.report(validation_accuracy, step=epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    return best_validation_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: I’ve set `n_trials=2` so you can run a quick test, but if you want to actually tune the hyperparameters, you should increase this to at least 50—and ideally to several hundred, but it will take several hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 21:19:34,312] A new study created in memory with name: no-name-a48459d0-5e94-406c-88f9-e1bc884a62f9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 0.6379, train metric: 0.7310, valid metric: 0.7674\n",
      "Epoch 1/1, train loss: 0.5245, train metric: 0.7765, valid metric: 0.7928\n",
      "Epoch 1/1, train loss: 0.4782, train metric: 0.7976, valid metric: 0.7992\n",
      "Epoch 1/1, train loss: 0.4444, train metric: 0.8131, valid metric: 0.8180\n",
      "Epoch 1/1, train loss: 0.4185, train metric: 0.8249, valid metric: 0.8197\n",
      "Epoch 1/1, train loss: 0.3978, train metric: 0.8341, valid metric: 0.8434\n",
      "Epoch 1/1, train loss: 0.3801, train metric: 0.8421, valid metric: 0.8480\n",
      "Epoch 1/1, train loss: 0.3635, train metric: 0.8498, valid metric: 0.8281\n",
      "Epoch 1/1, train loss: 0.3501, train metric: 0.8558, valid metric: 0.8549\n",
      "Epoch 1/1, train loss: 0.3385, train metric: 0.8613, valid metric: 0.8684\n",
      "Epoch 1/1, train loss: 0.3270, train metric: 0.8660, valid metric: 0.8718\n",
      "Epoch 1/1, train loss: 0.3170, train metric: 0.8704, valid metric: 0.8714\n",
      "Epoch 1/1, train loss: 0.3070, train metric: 0.8751, valid metric: 0.8676\n",
      "Epoch 1/1, train loss: 0.3015, train metric: 0.8771, valid metric: 0.8472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 21:20:29,002] Trial 0 finished with value: 0.8718438744544983 and parameters: {'learning_rate': 0.05611516415334506, 'n_layers': 3, 'n_hidden': 118}. Best is trial 0 with value: 0.8718438744544983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 0.2921, train metric: 0.8814, valid metric: 0.8700\n",
      "Epoch 1/1, train loss: 0.6367, train metric: 0.7331, valid metric: 0.7501\n",
      "Epoch 1/1, train loss: 0.5668, train metric: 0.7583, valid metric: 0.7631\n",
      "Epoch 1/1, train loss: 0.5447, train metric: 0.7674, valid metric: 0.7765\n",
      "Epoch 1/1, train loss: 0.5293, train metric: 0.7748, valid metric: 0.7797\n",
      "Epoch 1/1, train loss: 0.5186, train metric: 0.7789, valid metric: 0.7738\n",
      "Epoch 1/1, train loss: 0.5109, train metric: 0.7830, valid metric: 0.7894\n",
      "Epoch 1/1, train loss: 0.5046, train metric: 0.7853, valid metric: 0.7897\n",
      "Epoch 1/1, train loss: 0.4998, train metric: 0.7879, valid metric: 0.7919\n",
      "Epoch 1/1, train loss: 0.4961, train metric: 0.7886, valid metric: 0.7948\n",
      "Epoch 1/1, train loss: 0.4925, train metric: 0.7907, valid metric: 0.7884\n",
      "Epoch 1/1, train loss: 0.4895, train metric: 0.7925, valid metric: 0.8016\n",
      "Epoch 1/1, train loss: 0.4865, train metric: 0.7935, valid metric: 0.7924\n",
      "Epoch 1/1, train loss: 0.4862, train metric: 0.7942, valid metric: 0.7899\n",
      "Epoch 1/1, train loss: 0.4824, train metric: 0.7949, valid metric: 0.7844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 21:21:15,807] Trial 1 finished with value: 0.8016385436058044 and parameters: {'learning_rate': 0.15751320499779728, 'n_layers': 1, 'n_hidden': 48}. Best is trial 0 with value: 0.8718438744544983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 0.4792, train metric: 0.7962, valid metric: 0.7894\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler,\n",
    "                            pruner=pruner)\n",
    "study.optimize(objective, n_trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8718438744544983"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05611516415334506, 'n_layers': 3, 'n_hidden': 118}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope you enjoyed this chapter!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
